{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile State Usage Data\n",
    "Loops through a list of all states an pulls USGS water use data for each state into a single table. \n",
    "\n",
    "#### Requires: pandas and us (installed via pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import os, urllib\n",
    "import pandas as pd\n",
    "from us import states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the output csv file\n",
    "outFilename = \"../Data/AllStatesUsage2010.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(state_abbr,year=2010):\n",
    "    '''Downloads USGS data and creates a tidy dataframe of all the usage data for the state'''\n",
    "    \n",
    "    #Set the data URL path and parameters and construct the url\n",
    "    path = 'https://waterdata.usgs.gov/{}/nwis/water_use?'.format(state_abbr)\n",
    "    values = {'format':'rdb',\n",
    "             'rdb_compression':'value',\n",
    "             'wu_area':'County',\n",
    "             'wu_year': year,\n",
    "             'wu_county':'ALL',\n",
    "             'wu_county_nms':'--ALL+Counties--',\n",
    "             'wu_category_nms':'--ALL+Categories--'\n",
    "            }\n",
    "    url = path + urllib.urlencode(values)\n",
    "    \n",
    "    #Pull data in using the URL and remove the 2nd row of headers\n",
    "    dfRaw = pd.read_table(url,comment='#',header=[0,1],na_values='-')\n",
    "    dfRaw.columns = dfRaw.columns.droplevel(level=1)\n",
    "\n",
    "    #Tidy the data: transform so data in each usage column become row values with a new column listing the usage type\n",
    "    rowHeadings = ['county_cd', 'county_nm', 'state_cd', 'state_name', 'year']\n",
    "    dfTidy = pd.melt(dfRaw,id_vars=rowHeadings,value_name='MGal',var_name='Group')\n",
    "\n",
    "    #Remove rows that don't have volume data (i.e. keep only columns with 'Mgal' in the name)\n",
    "    dfTidy = dfTidy[dfTidy['Group'].str.contains('Mgal')].copy(deep=True)\n",
    "\n",
    "    #Change the type of the MGal column to float \n",
    "    dfTidy['MGal'] = dfTidy.MGal.astype('float')\n",
    "    \n",
    "    #Summarize county data for the whole state\n",
    "    stateSummary = dfTidy.groupby(['Group'])['MGal'].sum()\n",
    "    \n",
    "    #Convert to a dataframe\n",
    "    dfState = pd.DataFrame(stateSummary)\n",
    "    \n",
    "    #Rename the MGal column to the state abbreviation\n",
    "    dfState.columns = [state_abbr]\n",
    "    \n",
    "    #Return the dataframe\n",
    "    return dfState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data for the first state\n",
    "abbr = states.STATES_CONTINENTAL[0].abbr\n",
    "dfAll = getData(abbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AK\n",
      "Processing AZ\n",
      "Processing AR\n",
      "Processing CA\n",
      "Processing CO\n",
      "Processing CT\n",
      "Processing DE\n",
      "Processing DC\n",
      "Processing FL\n",
      "Processing GA\n",
      "Processing ID\n",
      "Processing IL\n",
      "Processing IN\n",
      "Processing IA\n",
      "Processing KS\n",
      "Processing KY\n",
      "Processing LA\n",
      "Processing ME\n",
      "Processing MD\n",
      "Processing MA\n",
      "Processing MI\n",
      "Processing MN\n",
      "Processing MS\n",
      "Processing MO\n",
      "Processing MT\n",
      "Processing NE\n",
      "Processing NV\n",
      "Processing NH\n",
      "Processing NJ\n",
      "Processing NM\n",
      "Processing NY\n",
      "Processing NC\n",
      "Processing ND\n",
      "Processing OH\n",
      "Processing OK\n",
      "Processing OR\n",
      "Processing PA\n",
      "Processing RI\n",
      "Processing SC\n",
      "Processing SD\n",
      "Processing TN\n",
      "Processing TX\n",
      "Processing UT\n",
      "Processing VT\n",
      "Processing VA\n",
      "Processing WA\n",
      "Processing WV\n",
      "Processing WI\n",
      "Processing WY\n"
     ]
    }
   ],
   "source": [
    "#Loop through states\n",
    "for state in states.STATES_CONTINENTAL[1:]:\n",
    "    abbr = state.abbr\n",
    "    print(\"Processing {}\".format(abbr))\n",
    "    dfState = getData(abbr)\n",
    "    dfAll = pd.merge(dfAll,dfState,how='inner',left_index='Group',right_index='Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.to_csv(outFilename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
