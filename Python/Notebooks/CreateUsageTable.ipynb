{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import USGS use data & Create usage table\n",
    "Here we download the raw usage data for years 2000, 2005, and 2010 from the USGS usage site and synthesize all data into a flat table listing: year, FIPS code, and total annual withdrawals by sector in MGal/day (*so these need to be ajdusted for yearly sums!)\n",
    "\n",
    "The steps required include:\n",
    "* Pulling the raw data file, in tab-delimted format, from the USGS server into a pandas dataframe.\n",
    "* Adjusting field names to a standard nomenclature:\n",
    "    * Adding year columns to 2000 and 2005 datasets.\n",
    "    * For year 2000, remapping 'IT', 'LA', 'LS', and 'PE' fields to 'IC', 'AQ', 'LI' and 'PC', respectively([reference]( https://water.usgs.gov/watuse/data/2000/datadict.html)).\n",
    "        * IT -> IC (Irrigated cropland)\n",
    "        * LA -> AQ (Aquaculture)\n",
    "        * LS -> LI (Livestock)\n",
    "        * PE -> PC (Thermoelectric power closed-loop)\n",
    "    * For year 2005, remapping 'LA' and 'LS' fields to 'AQ' and 'LI', respectively([reference]( https://water.usgs.gov/watuse/data/2005/datadict.html)). \n",
    "        * LA -> AQ (Aquaculture)\n",
    "        * LS -> LI (Livestock)\n",
    "* Re-arranging data into a tidy format to facilitate additional analyses.\n",
    "    * Care must be taken that the FIPS codes are preserved as text, not numbers\n",
    "* Appending all tables into a single dataframe, with records tagged by the year of the dataset.\n",
    "* Removing extraneous fields, keeping only the sector total columns:\n",
    "    \n",
    "The resulting table will be formatted as follows:\n",
    "\n",
    "| YEAR | FIPS | UseClass | SourceClass | SourceType | Amount |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | \n",
    "| 2000 | 01001 | PublicSupply | Surface  | Fresh |0.00 |\n",
    "| 2000 | 01001 | Industrial | Ground  | Saline |0.00 |\n",
    "\n",
    "This table can then be summarized and joined, by YEAR and FIPS code, to other accounting data tables and summarized by state. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import modules required for analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create prefix remapping dictionaries to standardize column names for all years to 2010\n",
    "remapDict = {'IT-':'IR-', #Irrigated (total)\n",
    "             'LA-':'AQ-', #Aquaculture\n",
    "             'LS-':'LI-', #Livestock\n",
    "             'PE-':'PC-', #Closed-loop thermo electric\n",
    "             'Wtotl':'WTotl' #Capitalization mismatch\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function for importing a table and standardizing all field names\n",
    "def importTable(year, remapDict):\n",
    "    \n",
    "    #Set the download URL using with the year\n",
    "    theURL = 'http://water.usgs.gov/watuse/data/{0}/usco{0}.txt'.format(year) \n",
    "    \n",
    "    #Download the dataset to a data frame (keeping the FIPS attribute as a string)\n",
    "    df = pd.read_table(theURL.format(year),dtype={'FIPS':str})\n",
    "    \n",
    "    #Remove the STATE, STATEFIPS and COUNTYFIPS columns (Not needed)\n",
    "    df.drop(\"STATE\",axis=1,inplace=True)\n",
    "    df.drop(\"STATEFIPS\",axis=1,inplace=True)\n",
    "    df.drop(\"COUNTYFIPS\",axis=1,inplace=True)\n",
    "    \n",
    "    #Use the remap dictionary to rename columns\n",
    "    \n",
    "    #Get the current column names as a list\n",
    "    colNames = df.columns.values.tolist()\n",
    "    \n",
    "    for inFld,outFld in remapDict.items():\n",
    "        #This loops through each item in colNames and replaces it with a revised one\n",
    "        colNames_update = [x.replace(inFld,outFld) for x in colNames]\n",
    "        colNames = colNames_update\n",
    "\n",
    "    #Update the column names in the data frame\n",
    "    df.columns = colNames\n",
    "    \n",
    "    #Add year field, if not present\n",
    "    if \"YEAR\" not in df.columns.values: \n",
    "        df.insert(1,\"YEAR\",year)\n",
    "        \n",
    "    #Remove unnamed columns\n",
    "    if \"Unnamed\" in df.columns.values[-1]:\n",
    "        df.drop(df.columns.values[-1],axis=1,inplace=True)\n",
    "        \n",
    "    #Status\n",
    "    print \"{} records and {} attributes returned for year {}\".format(df.shape[0],df.shape[1],year)\n",
    "        \n",
    "    #Return the data frame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3222 records and 68 attributes returned for year 2000\n",
      "3224 records and 105 attributes returned for year 2005\n",
      "3224 records and 114 attributes returned for year 2010\n"
     ]
    }
   ],
   "source": [
    "#Get the tables\n",
    "df2000 = importTable(2000,remapDict)\n",
    "df2005 = importTable(2005,remapDict)\n",
    "df2010 = importTable(2010,remapDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"Melt\" data so each use/class/type becomes a new row\n",
    "df2000m = pd.melt(df2000,id_vars=['FIPS','YEAR'],var_name='Class',value_name='Amount')\n",
    "df2005m = pd.melt(df2005,id_vars=['FIPS','YEAR'],var_name='Class',value_name='Amount')\n",
    "df2010m = pd.melt(df2010,id_vars=['FIPS','YEAR'],var_name='Class',value_name='Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all records into a single table\n",
    "dfUse = pd.concat([df2000m, df2005m, df2010m],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create remap dictionaries\n",
    "useClassMap = {'TP':'Population',\n",
    "               'PS':'PublicSupply',\n",
    "               'DO':'Domestic',\n",
    "               'IN':'Industrial',\n",
    "               'IR':'Irrigation',\n",
    "               'IC':'Irrigation_Crop',\n",
    "               'IG':'Irrigation_Golf',\n",
    "               'LI':'Livestock',\n",
    "               'AQ':'Aquaculture',\n",
    "               'MI':'Mining',\n",
    "               'PT':'ThermoElec',\n",
    "               'PO':'ThermoElec_OnceThru',\n",
    "               'PC':'ThermoElec_Recirc',\n",
    "               'TO':'Total'\n",
    "              }\n",
    "\n",
    "srcClassMap = {'-WGW':'Groundwater',\n",
    "               '-WSW':'Surface'\n",
    "              }\n",
    "\n",
    "srcTypeMap = {'Fr':'Fresh',\n",
    "              'Sa':'Saline',\n",
    "              'To':'Total',\n",
    "              'WFtTo':'TotFresh',\n",
    "              'WSaTo':'TotSaline',\n",
    "              'WTotl':'TotWithdrawal'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the use classes\n",
    "for k,v in useClassMap.items():\n",
    "    dfUse.loc[dfUse.Class.str.startswith(k), 'UseClass'] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the source classes\n",
    "for k,v in srcClassMap.items():\n",
    "    dfUse.loc[dfUse.Class.str.contains(k), 'SrcClass'] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the source types\n",
    "for k,v in srcTypeMap.items():\n",
    "    dfUse.loc[dfUse.Class.str.endswith(k), 'SrcType'] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COUNTY'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK: List classes with null srcClass remaps\n",
    "dfUse[pd.isnull(dfUse['UseClass'])].Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TP-TotPop', 'PS-TOPop', 'DO-SSPop', 'IR-IrSpr', 'IR-IrMic',\n",
       "       'IR-IrSur', 'IR-IrTot', 'PS-GWPop', 'PS-SWPop', 'DO-PSDel',\n",
       "       'DO-TOTAL ', 'IC-IrSpr', 'IC-IrMic', 'IC-IrSur', 'IC-IrTot',\n",
       "       'IG-IrSpr', 'IG-IrMic', 'IG-IrSur', 'IG-IrTot', 'PT-Power',\n",
       "       'PO-Power', 'PC-Power', 'COUNTY', 'DO-SSPCp', 'DO-PSPCp'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK: List classes with null srcClass remaps\n",
    "dfUse[pd.isnull(dfUse['SrcClass'])].Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TP-TotPop', 'PS-TOPop', 'DO-SSPop', 'IR-IrSpr', 'IR-IrMic',\n",
       "       'IR-IrSur', 'IR-IrTot', 'PS-GWPop', 'PS-SWPop', 'DO-PSDel',\n",
       "       'DO-TOTAL ', 'IC-IrSpr', 'IC-IrMic', 'IC-IrSur', 'IC-IrTot',\n",
       "       'IG-IrSpr', 'IG-IrMic', 'IG-IrSur', 'IG-IrTot', 'PT-Power',\n",
       "       'PO-Power', 'PC-Power', 'COUNTY', 'DO-SSPCp', 'DO-PSPCp'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK: List classes with null srcClass remaps\n",
    "dfUse[pd.isnull(dfUse['SrcType'])].Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows (axis = 0), with a null value in 'any' column\n",
    "dfUse.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the output location and filename\n",
    "dataDir = '../../Data'\n",
    "outFN = 'UsageDataTidy.csv'\n",
    "dfUse.to_csv(dataDir + os.sep + outFN,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check that the final merge contains all yearly columns\n",
    "s00 = set(df2000.columns.values.tolist())\n",
    "s05 = set(df2005.columns.values.tolist())\n",
    "s10 = set(df2010.columns.values.tolist())\n",
    "sXX = set(df.columns.values.tolist())\n",
    "print s00.issubset(sXX)\n",
    "print s05.issubset(sXX)\n",
    "print s10.issubset(sXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fix FIPS column\n",
    "dfUsage['FIPS'] = df['FIPS'].apply(lambda x: str(x).zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save as a CSV file\n",
    "dfUsage.to_csv(outFN,index_label=\"KEY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
